{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    DataProcessor,\n",
    "    InputExample,\n",
    "    glue_convert_examples_to_features,\n",
    ")\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-orleans",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "impressive-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = {\n",
    "    \"save_results_path\": 'outputs',\n",
    "    \"pretrain_dir\": 'models',\n",
    "    \"bert_model\": \"/fred/oz064/xcai/paper1/pytorch/huggingface/bert-base-uncased\",\n",
    "    \"max_seq_length\": None,\n",
    "    \"feat_dim\": 768,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"freeze_bert_parameters\": True,\n",
    "    \"save_model\": True,\n",
    "    \"save_results\": True,\n",
    "    \"dataset\": \"oos\",\n",
    "    \"known_cls_ratio\": 0.75,\n",
    "    \"labeled_ratio\": 1.0,\n",
    "    \"method\": None,\n",
    "    \"seed\": 0,\n",
    "    \"gpu_id\": '0',\n",
    "    \"lr\": 2e-5,\n",
    "    \"num_train_epochs\": 100.0,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 64,\n",
    "    \"wait_patient\": 10,\n",
    "    \"lr_boundary\": 0.05,\n",
    "    \"num_labels\": 10,\n",
    "}\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-trauma",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accompanied-journal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/data_full.json'\n",
    "def data_read(data_path):\n",
    "    reader = []\n",
    "    with open (data_path) as f:\n",
    "        reader = json.load(f)\n",
    "    return reader      \n",
    "data_read(data_path).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-cambodia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['translate', 'transfer', 'timer', 'definition', 'meaning_of_life', 'insurance_change', 'find_phone', 'travel_alert', 'pto_request', 'improve_credit_score', 'fun_fact', 'change_language', 'payday', 'replacement_card_duration', 'time', 'application_status', 'flight_status', 'flip_coin', 'change_user_name', 'where_are_you_from', 'shopping_list_update', 'what_can_i_ask_you', 'maybe', 'oil_change_how', 'restaurant_reservation', 'balance', 'confirm_reservation', 'freeze_account', 'rollover_401k', 'who_made_you', 'distance', 'user_name', 'timezone', 'next_song', 'transactions', 'restaurant_suggestion', 'rewards_balance', 'pay_bill', 'spending_history', 'pto_request_status', 'credit_score', 'new_card', 'lost_luggage', 'repeat', 'mpg', 'oil_change_when', 'yes', 'travel_suggestion', 'insurance', 'todo_list_update', 'reminder', 'change_speed', 'tire_pressure', 'no', 'apr', 'nutrition_info', 'calendar', 'uber', 'calculator', 'date', 'carry_on', 'pto_used', 'schedule_maintenance', 'travel_notification', 'sync_device', 'thank_you', 'roll_dice', 'food_last', 'cook_time', 'reminder_update', 'report_lost_card', 'ingredient_substitution', 'make_call', 'alarm', 'todo_list', 'change_accent', 'w2', 'bill_due', 'calories', 'damaged_card', 'restaurant_reviews', 'routing', 'do_you_have_pets', 'schedule_meeting', 'gas_type', 'plug_type', 'tire_change', 'exchange_rate', 'next_holiday', 'change_volume', 'who_do_you_work_for', 'credit_limit', 'how_busy', 'accept_reservations', 'order_status', 'pin_change', 'goodbye', 'account_blocked', 'what_song', 'international_fees', 'last_maintenance', 'meeting_schedule', 'ingredients_list', 'report_fraud', 'measurement_conversion', 'smart_home', 'book_hotel', 'current_location', 'weather', 'taxes', 'min_payment', 'whisper_mode', 'cancel', 'international_visa', 'vaccines', 'pto_balance', 'directions', 'spelling', 'greeting', 'reset_settings', 'what_is_your_name', 'direct_deposit', 'interest_rate', 'credit_limit_change', 'what_are_your_hobbies', 'book_flight', 'shopping_list', 'text', 'bill_balance', 'share_location', 'redeem_rewards', 'play_music', 'calendar_update', 'are_you_a_bot', 'gas', 'expiration_date', 'update_playlist', 'cancel_reservation', 'tell_joke', 'change_ai_name', 'how_old_are_you', 'car_rental', 'jump_start', 'meal_suggestion', 'recipe', 'income', 'order', 'traffic', 'order_checks', 'card_declined', 'oos']\n"
     ]
    }
   ],
   "source": [
    "# data generation\n",
    "train_data = data_read(data_path)[\"train\"]\n",
    "val_data = data_read(data_path)[\"val\"]\n",
    "test_data = data_read(data_path)[\"test\"]\n",
    "oos_train_data = data_read(data_path)[\"oos_train\"]\n",
    "oos_val_data = data_read(data_path)[\"oos_val\"]\n",
    "oos_test_data = data_read(data_path)[\"oos_test\"]\n",
    "\n",
    "# data label generation\n",
    "def label_generator(train_data, oos_train_data):\n",
    "    data_label = []\n",
    "    for index in range(0,len(train_data)) :\n",
    "        if train_data[index][1] not in data_label:\n",
    "            data_label.append(train_data[index][1])\n",
    "            index = index + 1\n",
    "    data_label.append(oos_train_data[0][1])\n",
    "    return data_label\n",
    "idx_to_type = label_generator(train_data, oos_train_data)\n",
    "print(idx_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(oos_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleased-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DatasetProcessor(DataProcessor):\n",
    "\n",
    "# #     def get_examples(self, data_dir, mode):\n",
    "# #         if mode == 'train':\n",
    "# #             return self._create_examples(\n",
    "# #                 self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "# #         elif mode == 'eval':\n",
    "# #             return self._create_examples(\n",
    "# #                 self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"train\")\n",
    "# #         elif mode == 'test':\n",
    "# #             return self._create_examples(\n",
    "# #                 self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "# #     def get_labels(self, data_dir):\n",
    "# #         \"\"\"See base class.\"\"\"\n",
    "# #         import pandas as pd\n",
    "# #         test = pd.read_csv(os.path.join(data_dir, \"train.tsv\"), sep=\"\\t\")\n",
    "# #         labels = np.unique(np.array(test['label']))\n",
    "            \n",
    "# #         return label\n",
    "    \n",
    "#     def _create_examples(self, lines, set_type):\n",
    "#         \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "#         examples = []\n",
    "#         for (i, line) in enumerate(lines):\n",
    "#             if i == 0:\n",
    "#                 continue\n",
    "#             if len(line) != 2:\n",
    "#                 continue\n",
    "#             guid = \"%s-%s\" % (set_type, i)\n",
    "#             text_a = line[0]\n",
    "#             label = line[1]\n",
    "\n",
    "#             examples.append(\n",
    "#                 InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "#         return examples\n",
    "\n",
    "# def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "#     \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "#     label_map = {}\n",
    "#     for i, label in enumerate(label_list):\n",
    "#         label_map[label] = i\n",
    "\n",
    "#     features = []\n",
    "#     for (ex_index, example) in enumerate(examples):\n",
    "#         tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "#         tokens_b = None\n",
    "#         if example.text_b:\n",
    "#             tokens_b = tokenizer.tokenize(example.text_b)\n",
    "#             # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "#             # length is less than the specified length.\n",
    "#             # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "#             _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "#         else:\n",
    "#             # Account for [CLS] and [SEP] with \"- 2\"\n",
    "#             if len(tokens_a) > max_seq_length - 2:\n",
    "#                 tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "#         # The convention in BERT is:\n",
    "#         # (a) For sequence pairs:\n",
    "#         #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "#         #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "#         # (b) For single sequences:\n",
    "#         #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "#         #  type_ids: 0   0   0   0  0     0 0\n",
    "#         #\n",
    "#         # Where \"type_ids\" are used to indicate whether this is the first\n",
    "#         # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "#         # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "#         # embedding vector (and position vector). This is not *strictly* necessary\n",
    "#         # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "#         # it easier for the model to learn the concept of sequences.\n",
    "#         #\n",
    "#         # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "#         # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "#         # the entire model is fine-tuned.\n",
    "#         tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "#         segment_ids = [0] * len(tokens)\n",
    "\n",
    "#         if tokens_b:\n",
    "#             tokens += tokens_b + [\"[SEP]\"]\n",
    "#             segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "#         input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "#         # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "#         # tokens are attended to.\n",
    "#         input_mask = [1] * len(input_ids)\n",
    "\n",
    "#         # Zero-pad up to the sequence length.\n",
    "#         padding = [0] * (max_seq_length - len(input_ids))\n",
    "#         input_ids += padding\n",
    "#         input_mask += padding\n",
    "#         segment_ids += padding\n",
    "\n",
    "#         assert len(input_ids) == max_seq_length\n",
    "#         assert len(input_mask) == max_seq_length\n",
    "#         assert len(segment_ids) == max_seq_length\n",
    "\n",
    "#         label_id = label_map[example.label]\n",
    "#         # if ex_index < 5:\n",
    "#         #     logger.info(\"*** Example ***\")\n",
    "#         #     logger.info(\"guid: %s\" % (example.guid))\n",
    "#         #     logger.info(\"tokens: %s\" % \" \".join(\n",
    "#         #         [str(x) for x in tokens]))\n",
    "#         #     logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "#         #     logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "#         #     logger.info(\n",
    "#         #         \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "#         #     logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "#         features.append(\n",
    "#             InputFeatures(input_ids=input_ids,\n",
    "#                           input_mask=input_mask,\n",
    "#                           segment_ids=segment_ids,\n",
    "#                           label_id=label_id))\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collective-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "requested-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InputExample(guid='0', text_a=train_data[0][0], label=train_data[0][1])\n",
    "def create_examples(data):\n",
    "    examples = []\n",
    "    for i, e in enumerate(data):\n",
    "        examples.append(InputExample(guid = str(i), text_a=e[0], label=e[1]))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unnecessary-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[InputExample(guid='0', text_a='what expression would i use to say i love you if i were an italian', text_b=None, label='translate'), InputExample(guid='1', text_a=\"can you tell me how to say 'i do not speak much spanish', in spanish\", text_b=None, label='translate'), InputExample(guid='2', text_a=\"what is the equivalent of, 'life is good' in french\", text_b=None, label='translate')]\n"
     ]
    }
   ],
   "source": [
    "examples = create_examples(train_data)\n",
    "print(examples[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "agreed-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaders(tokenizer, data_path):\n",
    "    def generate_dataloader_inner(examples, data_type='train'):\n",
    "        features = glue_convert_examples_to_features(\n",
    "            examples,\n",
    "            tokenizer,\n",
    "            label_list = idx_to_type,\n",
    "            max_length = 64,\n",
    "            output_mode = 'classification'\n",
    "        )\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.LongTensor([f.input_ids for f in features]),\n",
    "            torch.LongTensor([f.attention_mask for f in features]),\n",
    "            torch.LongTensor([f.token_type_ids for f in features]),\n",
    "            torch.LongTensor([f.label for f in features])   \n",
    "        )\n",
    "        if data_type == 'train':\n",
    "            sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        else:\n",
    "            sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, sampler = sampler, batch_size = 32\n",
    "        )\n",
    "        return dataloader\n",
    "    \n",
    "    # notice here class OOS is always the last label\n",
    "    train_examples = create_examples(data_read(data_path)[\"train\"]+ data_read(data_path)[\"oos_train\"])\n",
    "    print('Load Example Finish')\n",
    "    train_loader = generate_dataloader_inner(train_examples, data_type='train')\n",
    "    print('Generate DataLoader Finish')\n",
    "\n",
    "    valid_examples = create_examples(data_read(data_path)[\"val\"] + data_read(data_path)[\"oos_val\"])\n",
    "    print('Load Example Finish')\n",
    "    valid_loader = generate_dataloader_inner(valid_examples, data_type='valid')\n",
    "    print('Generate DataLoader Finish')   \n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "heard-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Example Finish\n",
      "Generate DataLoader Finish\n",
      "Load Example Finish\n",
      "Generate DataLoader Finish\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"/fred/oz064/xcai/paper1/pytorch/huggingface/bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "train_loader, valid_loader = generate_dataloaders(tokenizer, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "collective-blogger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([ 9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])\n",
      "tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17])\n",
      "tensor([17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19])\n",
      "tensor([19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20])\n",
      "tensor([20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22])\n",
      "tensor([22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])\n",
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25])\n",
      "tensor([25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27])\n",
      "tensor([27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28,\n",
      "        28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28])\n",
      "tensor([28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30])\n",
      "tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31])\n",
      "tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33])\n",
      "tensor([33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35])\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36,\n",
      "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36])\n",
      "tensor([36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
      "        37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38])\n",
      "tensor([38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39])\n",
      "tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41])\n",
      "tensor([41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
      "        42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43])\n",
      "tensor([43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44,\n",
      "        44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44])\n",
      "tensor([44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
      "        45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46])\n",
      "tensor([46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47,\n",
      "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47])\n",
      "tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
      "        48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49])\n",
      "tensor([49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
      "        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51])\n",
      "tensor([51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52,\n",
      "        52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52])\n",
      "tensor([52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54])\n",
      "tensor([54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55])\n",
      "tensor([56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
      "        56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57])\n",
      "tensor([57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
      "        58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59])\n",
      "tensor([59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60,\n",
      "        60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60])\n",
      "tensor([60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62])\n",
      "tensor([62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63,\n",
      "        63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63])\n",
      "tensor([64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
      "        64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65])\n",
      "tensor([65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66,\n",
      "        66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67])\n",
      "tensor([67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "        68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68])\n",
      "tensor([68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69,\n",
      "        69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70])\n",
      "tensor([70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71,\n",
      "        71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71])\n",
      "tensor([72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72,\n",
      "        72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73])\n",
      "tensor([73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74,\n",
      "        74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75])\n",
      "tensor([75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76,\n",
      "        76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76])\n",
      "tensor([76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77,\n",
      "        77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78])\n",
      "tensor([78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79,\n",
      "        79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79])\n",
      "tensor([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "        80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81])\n",
      "tensor([81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
      "        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83])\n",
      "tensor([83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84,\n",
      "        84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84])\n",
      "tensor([84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85,\n",
      "        85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86])\n",
      "tensor([86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87,\n",
      "        87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87])\n",
      "tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88,\n",
      "        88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89])\n",
      "tensor([89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90,\n",
      "        90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91])\n",
      "tensor([91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92,\n",
      "        92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92])\n",
      "tensor([92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93,\n",
      "        93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94])\n",
      "tensor([94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95,\n",
      "        95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95])\n",
      "tensor([96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,\n",
      "        96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97])\n",
      "tensor([97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
      "        98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99])\n",
      "tensor([ 99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100])\n",
      "tensor([100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102,\n",
      "        102, 102, 102, 102])\n",
      "tensor([102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103])\n",
      "tensor([104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104,\n",
      "        104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105])\n",
      "tensor([105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        107, 107, 107, 107])\n",
      "tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "        107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
      "        108, 108, 108, 108])\n",
      "tensor([108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
      "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110,\n",
      "        110, 110, 110, 110])\n",
      "tensor([110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 111, 111,\n",
      "        111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111,\n",
      "        111, 111, 111, 111])\n",
      "tensor([112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112,\n",
      "        112, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113])\n",
      "tensor([113, 113, 113, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,\n",
      "        115, 115, 115, 115])\n",
      "tensor([115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "        115, 115, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116,\n",
      "        116, 116, 116, 116])\n",
      "tensor([116, 116, 116, 116, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
      "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118])\n",
      "tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 119, 119,\n",
      "        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,\n",
      "        119, 119, 119, 119])\n",
      "tensor([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121])\n",
      "tensor([121, 121, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "        123, 123, 123, 123])\n",
      "tensor([123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "        124, 124, 124, 124])\n",
      "tensor([124, 124, 124, 124, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 126, 126, 126, 126,\n",
      "        126, 126, 126, 126])\n",
      "tensor([126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127, 127])\n",
      "tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129])\n",
      "tensor([129, 129, 129, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130,\n",
      "        131, 131, 131, 131])\n",
      "tensor([131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        131, 131, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132])\n",
      "tensor([132, 132, 132, 132, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134])\n",
      "tensor([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135, 135,\n",
      "        135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,\n",
      "        135, 135, 135, 135])\n",
      "tensor([136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,\n",
      "        136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137, 137, 137])\n",
      "tensor([137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        139, 139, 139, 139])\n",
      "tensor([139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
      "        139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140])\n",
      "tensor([140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142])\n",
      "tensor([142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143])\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,\n",
      "        144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145,\n",
      "        145, 145, 145, 145])\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,\n",
      "        146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,\n",
      "        147, 147, 147, 147])\n",
      "tensor([147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,\n",
      "        148, 148, 148, 148])\n",
      "tensor([148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150])\n"
     ]
    }
   ],
   "source": [
    "for batch in valid_loader:\n",
    "# for batch in train_loader:\n",
    "    print(batch[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "frequent-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_loss(x, y, num_cls, w, \n",
    "             reuse=False, alpha=0.25, beta=0.25, scale=64, \n",
    "             lamb=0.05, name='cos_margin_loss'):\n",
    "    '''\n",
    "    x: B x D - features\n",
    "    y: B - labels\n",
    "    num_cls: 1 - total class number, the last cls being out of scope\n",
    "    w: num_cls x D - mean feature vectors (centroids)\n",
    "    alpah: 1 - in scope margin\n",
    "    beta: 1 - out of scope margin\n",
    "    scale: 1 - scaling paramter\n",
    "    ''' \n",
    "    #normalize the feature and weight\n",
    "    #(B,D)\n",
    "    x_feat_norm = F.normalize(x,p=2,dim=1,eps=1e-12)\n",
    "    #(D,num_cls)\n",
    "    w_feat_norm = torch.transpose(F.normalize(w,p=2,dim=1,eps=1e-12), 0, 1)\n",
    "\n",
    "    # get the scores after normalization \n",
    "    #(B,num_cls)\n",
    "    xw_norm = torch.matmul(x_feat_norm, w_feat_norm)  # cosine similarity\n",
    "\n",
    "    # xbj's loss, first row, adjust the cosine similarity by a margin, only apply to in-scope instances\n",
    "    xw_norm[:, :-1] -= alpha #(B,num_cls)\n",
    "#     xw_norm[:, -1] -= alpha #(B,num_cls)\n",
    "\n",
    "    # margin based softmax loss\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    ce_loss = loss_fn(xw_norm, y)\n",
    "    ce_loss[y == 150] = 0\n",
    "#     print(\"ce_loss shape: \", ce_loss.shape)\n",
    "    \n",
    "    # xbj loss, second row, only applies to out of scope instances\n",
    "    out_of_scope_loss_part2 = torch.max(xw_norm[:, :-1] - alpha, dim=1)[0] - xw_norm[:, -1]\n",
    "    out_of_scope_loss_part2[out_of_scope_loss_part2 < 0] = 0\n",
    "#     print(\"out_of_scope_loss_part2 shape: \", out_of_scope_loss_part2.shape)\n",
    "    out_of_scope_loss = lamb * (1 - xw_norm[:, -1]) + out_of_scope_loss_part2\n",
    "#     print(\"out_of_scope_loss shape: \", out_of_scope_loss.shape)\n",
    "       \n",
    "    out_of_scope_loss[y < 150] = 0\n",
    "    \n",
    "    loss = torch.mean(ce_loss + out_of_scope_loss)\n",
    "    \n",
    "    return loss \n",
    "\n",
    "def predict(x, w, alpha=0.25):\n",
    "    '''\n",
    "    x: B x D - features\n",
    "    w: num_cls x D - mean feature vectors (centroids)\n",
    "    ''' \n",
    "    #normalize the feature and weight\n",
    "    #(B,D)\n",
    "#     print(\"x.size():\", x.size())\n",
    "    x_feat_norm = F.normalize(x,p=2,dim=1,eps=1e-12)\n",
    "    #(D,num_cls)\n",
    "    w_feat_norm = torch.transpose(F.normalize(w,p=2,dim=1,eps=1e-12), 0, 1)\n",
    "\n",
    "    # get the scores after normalization \n",
    "    #(B,num_cls)\n",
    "    xw_norm = torch.matmul(x_feat_norm, w_feat_norm)  # cosine similarity\n",
    "\n",
    "    xw_norm[:, :-1] -= alpha\n",
    "    \n",
    "    preds = xw_norm.max(1)[1]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sealed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BERTModel (pl.LightningModule):\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  pretrained_path,\n",
    "#                  train_loader,\n",
    "#                  valid_loader):\n",
    "#         super(BERTModel, self).__init__()\n",
    "#         self.train_loader = train_loader\n",
    "#         self.valid_loader = valid_loader\n",
    "        \n",
    "#         config = BertConfig.from_json_file(pretrained_path + '/config.json')\n",
    "#         config.num_labels = len(idx_to_type)\n",
    "#         print(config)\n",
    "        \n",
    "#         # pretrained model\n",
    "#         self.ptm = BertForSequenceClassification.from_pretrained(\n",
    "#             os.path.join(retrained_path, 'pytorch_model.bin')\n",
    "#             config = config\n",
    "#         )\n",
    "        \n",
    "#         # loss function\n",
    "#         self.criterion = DCMLLoss()\n",
    "        \n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#         return self.ptm(\n",
    "#             input_ids = input_ids,\n",
    "#             attention_mask = attention_mask,\n",
    "#             token_type_ids = token_type_ids   \n",
    "#         )[0]\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         input_ids, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "macro-pencil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(args.bert_model)\n",
    "def get_optimizer(bert_model, args):\n",
    "    param_optimizer = list(bert_model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr = args.lr)   \n",
    "    return optimizer\n",
    "optimizer = get_optimizer(bert_model, args)\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id           \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "affecting-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing centroids...\n"
     ]
    }
   ],
   "source": [
    "def compute_centroids(dataloader, bert_model):\n",
    "    print(\"Computing centroids...\")\n",
    "    vectors = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(dataloader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "            token_type_ids = token_type_ids.to(DEVICE)\n",
    "            outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "            pooler_output = outputs.pooler_output\n",
    "            vectors.append(pooler_output.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    vectors = torch.cat(vectors, 0) # num_ins, feature_dim\n",
    "    labels = torch.cat(all_labels, 0) # num_ins\n",
    "    w = []\n",
    "    for i in range(151):\n",
    "        w.append(vectors[labels==i].mean(0, keepdim=True))\n",
    "    w = torch.cat(w, 0)\n",
    "    return w\n",
    "w = compute_centroids(valid_loader, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "noticed-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-boring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing centroids...\n",
      "[1] loss: 4.078\n",
      "accuracy:  0.8651612903225806 out of scope recall:  0.77 out of scope precision:  0.2862453531598513\n",
      "all_recalls:  [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.85, 0.85, 1.0, 1.0, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, 0.95, 0.3, 0.9, 1.0, 1.0, 1.0, 0.95, 1.0, 0.85, 0.65, 1.0, 0.75, 0.95, 1.0, 0.8, 1.0, 0.9, 1.0, 0.8, 1.0, 0.75, 1.0, 1.0, 0.8, 0.9, 0.95, 0.95, 0.85, 1.0, 1.0, 0.95, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.9, 1.0, 0.95, 1.0, 1.0, 0.95, 0.3, 0.95, 0.85, 1.0, 1.0, 1.0, 0.9, 0.8, 0.0, 0.95, 1.0, 0.55, 0.0, 1.0, 0.0, 1.0, 1.0, 0.65, 1.0, 0.75, 0.85, 1.0, 0.85, 0.95, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.7, 0.8, 0.9, 1.0, 0.9, 0.95, 0.45, 0.95, 0.95, 1.0, 0.95, 0.85, 0.95, 0.95, 1.0, 1.0, 0.0, 1.0, 0.95, 1.0, 1.0, 0.95, 0.0, 1.0, 0.65, 1.0, 0.85, 1.0, 0.95, 0.9, 1.0, 0.95, 0.55, 0.6, 1.0, 1.0, 0.95, 0.95, 0.6, 1.0, 1.0, 0.9, 0.95, 1.0, 0.85, 0.95, 1.0, 0.95]\n",
      "Computing centroids...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    w = compute_centroids(train_loader, bert_model).detach().to(DEVICE)\n",
    "    last_w = w.cpu()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_loader):\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "        token_type_ids = token_type_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        pooler_output  = outputs.pooler_output \n",
    "#         print(\"y.size():\", y.size())\n",
    "        \n",
    "        loss = cos_loss(pooler_output, labels, 151, w, alpha=0.25, beta=0.25, scale=64, name='cos_margin_loss')\n",
    "#         print(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('[%d] loss: %.3f' %\n",
    "          (epoch + 1, running_loss / (i+1)))\n",
    "    evaluate(valid_loader, last_w)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-harvey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "included-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([115968])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.958\n",
    "# 4.94\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dying-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.817741935483871 out of scope recall:  0.68 out of scope precision:  0.1883656509695291\n",
      "all_recalls:  [0.0, 0.95, 1.0, 0.65, 0.0, 1.0, 1.0, 0.85, 1.0, 0.85, 1.0, 0.0, 0.85, 0.9, 0.95, 0.95, 1.0, 1.0, 0.7, 0.0, 0.95, 0.95, 1.0, 1.0, 0.75, 0.65, 0.95, 0.9, 1.0, 0.0, 0.9, 0.8, 1.0, 1.0, 0.65, 0.95, 1.0, 0.75, 1.0, 0.8, 0.65, 0.75, 1.0, 0.8, 1.0, 1.0, 0.75, 0.8, 0.9, 0.95, 0.75, 1.0, 1.0, 0.85, 0.75, 0.5, 0.95, 1.0, 0.0, 0.95, 1.0, 0.95, 0.95, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.7, 1.0, 1.0, 0.85, 0.7, 0.95, 1.0, 1.0, 0.95, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9, 1.0, 0.0, 0.9, 1.0, 0.95, 0.5, 1.0, 1.0, 0.85, 0.95, 1.0, 0.95, 1.0, 0.85, 0.8, 0.8, 1.0, 0.9, 0.85, 0.05, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 0.5, 0.95, 0.85, 0.2, 1.0, 0.8, 0.95, 0.9, 1.0, 0.0, 1.0, 0.9, 0.9, 0.7, 1.0, 0.85, 0.8, 0.95, 0.8, 0.85, 0.75, 1.0, 0.85, 1.0, 0.75, 0.05, 1.0, 0.9, 0.95, 0.85, 0.95, 0.8, 0.95, 0.9, 0.95]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(dataloder, w):\n",
    "    w = w.to(DEVICE)\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(dataloder):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "            token_type_ids = token_type_ids.to(DEVICE)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "            pooler_output  = outputs.pooler_output \n",
    "\n",
    "            preds = predict(pooler_output, w).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "    preds = torch.cat(all_preds)\n",
    "    labels = torch.cat(all_labels)\n",
    "    accuracy = torch.sum(preds == labels).item() / labels.shape[0]\n",
    "    \n",
    "    all_recalls = [torch.sum(preds[labels==i] == labels[labels==i]).item() / torch.sum(labels == i).item() for i in range(150)]\n",
    "    out_of_scope_recall = torch.sum(preds[labels==150] == labels[labels==150]).item() / torch.sum(labels == 150).item()\n",
    "    out_of_scope_precision = torch.sum(preds[labels==150] == labels[labels==150]).item() / torch.sum(preds == 150).item()\n",
    "    print(\"accuracy: \", accuracy, \"out of scope recall: \", out_of_scope_recall, \"out of scope precision: \", out_of_scope_precision)\n",
    "    print(\"all_recalls: \", all_recalls)\n",
    "evaluate(valid_loader, last_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
