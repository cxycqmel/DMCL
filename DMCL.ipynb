{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    DataProcessor,\n",
    "    InputExample,\n",
    "    glue_convert_examples_to_features,\n",
    ")\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-orleans",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = {\n",
    "    \"save_results_path\": 'outputs',\n",
    "    \"pretrain_dir\": 'models',\n",
    "    \"bert_model\": \"/fred/oz064/xcai/paper1/pytorch/huggingface/bert-base-uncased\",\n",
    "    \"max_seq_length\": None,\n",
    "    \"feat_dim\": 768,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"freeze_bert_parameters\": True,\n",
    "    \"save_model\": True,\n",
    "    \"save_results\": True,\n",
    "    \"dataset\": \"oos\",\n",
    "    \"known_cls_ratio\": 0.75,\n",
    "    \"labeled_ratio\": 1.0,\n",
    "    \"method\": None,\n",
    "    \"seed\": 0,\n",
    "    \"gpu_id\": '0',\n",
    "    \"lr\": 2e-5,\n",
    "    \"num_train_epochs\": 100.0,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 64,\n",
    "    \"wait_patient\": 10,\n",
    "    \"lr_boundary\": 0.05,\n",
    "    \"num_labels\": 10,\n",
    "}\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-trauma",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-journal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/data_full.json'\n",
    "def data_read(data_path):\n",
    "    reader = []\n",
    "    with open (data_path) as f:\n",
    "        reader = json.load(f)\n",
    "    return reader      \n",
    "data_read(data_path).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empirical-cambodia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['translate', 'transfer', 'timer', 'definition', 'meaning_of_life', 'insurance_change', 'find_phone', 'travel_alert', 'pto_request', 'improve_credit_score', 'fun_fact', 'change_language', 'payday', 'replacement_card_duration', 'time', 'application_status', 'flight_status', 'flip_coin', 'change_user_name', 'where_are_you_from', 'shopping_list_update', 'what_can_i_ask_you', 'maybe', 'oil_change_how', 'restaurant_reservation', 'balance', 'confirm_reservation', 'freeze_account', 'rollover_401k', 'who_made_you', 'distance', 'user_name', 'timezone', 'next_song', 'transactions', 'restaurant_suggestion', 'rewards_balance', 'pay_bill', 'spending_history', 'pto_request_status', 'credit_score', 'new_card', 'lost_luggage', 'repeat', 'mpg', 'oil_change_when', 'yes', 'travel_suggestion', 'insurance', 'todo_list_update', 'reminder', 'change_speed', 'tire_pressure', 'no', 'apr', 'nutrition_info', 'calendar', 'uber', 'calculator', 'date', 'carry_on', 'pto_used', 'schedule_maintenance', 'travel_notification', 'sync_device', 'thank_you', 'roll_dice', 'food_last', 'cook_time', 'reminder_update', 'report_lost_card', 'ingredient_substitution', 'make_call', 'alarm', 'todo_list', 'change_accent', 'w2', 'bill_due', 'calories', 'damaged_card', 'restaurant_reviews', 'routing', 'do_you_have_pets', 'schedule_meeting', 'gas_type', 'plug_type', 'tire_change', 'exchange_rate', 'next_holiday', 'change_volume', 'who_do_you_work_for', 'credit_limit', 'how_busy', 'accept_reservations', 'order_status', 'pin_change', 'goodbye', 'account_blocked', 'what_song', 'international_fees', 'last_maintenance', 'meeting_schedule', 'ingredients_list', 'report_fraud', 'measurement_conversion', 'smart_home', 'book_hotel', 'current_location', 'weather', 'taxes', 'min_payment', 'whisper_mode', 'cancel', 'international_visa', 'vaccines', 'pto_balance', 'directions', 'spelling', 'greeting', 'reset_settings', 'what_is_your_name', 'direct_deposit', 'interest_rate', 'credit_limit_change', 'what_are_your_hobbies', 'book_flight', 'shopping_list', 'text', 'bill_balance', 'share_location', 'redeem_rewards', 'play_music', 'calendar_update', 'are_you_a_bot', 'gas', 'expiration_date', 'update_playlist', 'cancel_reservation', 'tell_joke', 'change_ai_name', 'how_old_are_you', 'car_rental', 'jump_start', 'meal_suggestion', 'recipe', 'income', 'order', 'traffic', 'order_checks', 'card_declined', 'oos']\n"
     ]
    }
   ],
   "source": [
    "# data generation\n",
    "train_data = data_read(data_path)[\"train\"]\n",
    "val_data = data_read(data_path)[\"val\"]\n",
    "test_data = data_read(data_path)[\"test\"]\n",
    "oos_train_data = data_read(data_path)[\"oos_train\"]\n",
    "oos_val_data = data_read(data_path)[\"oos_val\"]\n",
    "oos_test_data = data_read(data_path)[\"oos_test\"]\n",
    "\n",
    "# data label generation\n",
    "def label_generator(train_data, oos_train_data):\n",
    "    data_label = []\n",
    "    for index in range(0,len(train_data)) :\n",
    "        if train_data[index][1] not in data_label:\n",
    "            data_label.append(train_data[index][1])\n",
    "            index = index + 1\n",
    "    data_label.append(oos_train_data[0][1])\n",
    "    return data_label\n",
    "idx_to_type = label_generator(train_data, oos_train_data)\n",
    "print(idx_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InputExample(guid='0', text_a=train_data[0][0], label=train_data[0][1])\n",
    "def create_examples(data):\n",
    "    examples = []\n",
    "    for i, e in enumerate(data):\n",
    "        examples.append(InputExample(guid = str(i), text_a=e[0], label=e[1]))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unnecessary-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[InputExample(guid='0', text_a='what expression would i use to say i love you if i were an italian', text_b=None, label='translate'), InputExample(guid='1', text_a=\"can you tell me how to say 'i do not speak much spanish', in spanish\", text_b=None, label='translate'), InputExample(guid='2', text_a=\"what is the equivalent of, 'life is good' in french\", text_b=None, label='translate')]\n"
     ]
    }
   ],
   "source": [
    "examples = create_examples(train_data)\n",
    "print(examples[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agreed-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaders(tokenizer, data_path):\n",
    "    def generate_dataloader_inner(examples, data_type='train'):\n",
    "        features = glue_convert_examples_to_features(\n",
    "            examples,\n",
    "            tokenizer,\n",
    "            label_list = idx_to_type,\n",
    "            max_length = 64,\n",
    "            output_mode = 'classification'\n",
    "        )\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.LongTensor([f.input_ids for f in features]),\n",
    "            torch.LongTensor([f.attention_mask for f in features]),\n",
    "            torch.LongTensor([f.token_type_ids for f in features]),\n",
    "            torch.LongTensor([f.label for f in features])   \n",
    "        )\n",
    "        if data_type == 'train':\n",
    "            sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        else:\n",
    "            sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, sampler = sampler, batch_size = 32\n",
    "        )\n",
    "        return dataloader\n",
    "    \n",
    "    # notice here class OOS is always the last label\n",
    "    train_examples = create_examples(data_read(data_path)[\"train\"]+ data_read(data_path)[\"oos_train\"])\n",
    "    print('Load Example Finish')\n",
    "    train_loader = generate_dataloader_inner(train_examples, data_type='train')\n",
    "    print('Generate DataLoader Finish')\n",
    "\n",
    "    valid_examples = create_examples(data_read(data_path)[\"val\"] + data_read(data_path)[\"oos_val\"])\n",
    "    print('Load Example Finish')\n",
    "    valid_loader = generate_dataloader_inner(valid_examples, data_type='valid')\n",
    "    print('Generate DataLoader Finish')   \n",
    "\n",
    "    test_examples = create_examples(data_read(data_path)[\"test\"] + data_read(data_path)[\"oos_test\"])\n",
    "    print('Load Example Finish')\n",
    "    test_loader = generate_dataloader_inner(test_examples, data_type='valid')\n",
    "    print('Generate DataLoader Finish')\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "heard-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Example Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/skylake/software/Transformers/4.3.3-gni-2020.0-Python-3.8.5/lib/python3.8/site-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate DataLoader Finish\n",
      "Load Example Finish\n",
      "Generate DataLoader Finish\n",
      "Load Example Finish\n",
      "Generate DataLoader Finish\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"/fred/oz064/xcai/paper1/pytorch/huggingface/bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "train_loader, valid_loader, test_loader = generate_dataloaders(tokenizer, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electrical-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9])\n",
      "tensor([ 9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11])\n",
      "tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12])\n",
      "tensor([12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14])\n",
      "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])\n",
      "tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17])\n",
      "tensor([17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19])\n",
      "tensor([19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20])\n",
      "tensor([20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22])\n",
      "tensor([22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])\n",
      "tensor([24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25])\n",
      "tensor([25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27])\n",
      "tensor([27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28,\n",
      "        28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28])\n",
      "tensor([28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
      "        29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30])\n",
      "tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31,\n",
      "        31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31])\n",
      "tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33])\n",
      "tensor([33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35])\n",
      "tensor([35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36,\n",
      "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36])\n",
      "tensor([36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
      "        37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38])\n",
      "tensor([38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39])\n",
      "tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41])\n",
      "tensor([41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,\n",
      "        42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43])\n",
      "tensor([43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44,\n",
      "        44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44])\n",
      "tensor([44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
      "        45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46])\n",
      "tensor([46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47,\n",
      "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47])\n",
      "tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
      "        48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49])\n",
      "tensor([49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
      "        50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51])\n",
      "tensor([51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52,\n",
      "        52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52])\n",
      "tensor([52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54])\n",
      "tensor([54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55])\n",
      "tensor([56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
      "        56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57])\n",
      "tensor([57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
      "        58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59])\n",
      "tensor([59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60,\n",
      "        60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60])\n",
      "tensor([60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
      "        61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62])\n",
      "tensor([62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63,\n",
      "        63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63])\n",
      "tensor([64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
      "        64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65])\n",
      "tensor([65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66,\n",
      "        66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67])\n",
      "tensor([67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68,\n",
      "        68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68])\n",
      "tensor([68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69,\n",
      "        69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70])\n",
      "tensor([70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71,\n",
      "        71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71])\n",
      "tensor([72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72,\n",
      "        72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73])\n",
      "tensor([73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74,\n",
      "        74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75])\n",
      "tensor([75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76,\n",
      "        76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76])\n",
      "tensor([76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77,\n",
      "        77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78])\n",
      "tensor([78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79,\n",
      "        79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79])\n",
      "tensor([80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80,\n",
      "        80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81])\n",
      "tensor([81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
      "        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83])\n",
      "tensor([83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84,\n",
      "        84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84])\n",
      "tensor([84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85,\n",
      "        85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86])\n",
      "tensor([86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87,\n",
      "        87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87])\n",
      "tensor([88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88,\n",
      "        88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89])\n",
      "tensor([89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90,\n",
      "        90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91])\n",
      "tensor([91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92,\n",
      "        92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92])\n",
      "tensor([92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93,\n",
      "        93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94])\n",
      "tensor([94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95,\n",
      "        95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95])\n",
      "tensor([96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96,\n",
      "        96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97])\n",
      "tensor([97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
      "        98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99])\n",
      "tensor([ 99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,\n",
      "         99,  99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100])\n",
      "tensor([100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102,\n",
      "        102, 102, 102, 102])\n",
      "tensor([102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103])\n",
      "tensor([104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104,\n",
      "        104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105,\n",
      "        105, 105, 105, 105])\n",
      "tensor([105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106,\n",
      "        106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106,\n",
      "        107, 107, 107, 107])\n",
      "tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "        107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
      "        108, 108, 108, 108])\n",
      "tensor([108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
      "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110,\n",
      "        110, 110, 110, 110])\n",
      "tensor([110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 111, 111,\n",
      "        111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111,\n",
      "        111, 111, 111, 111])\n",
      "tensor([112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112,\n",
      "        112, 112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113])\n",
      "tensor([113, 113, 113, 113, 113, 113, 113, 113, 114, 114, 114, 114, 114, 114,\n",
      "        114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,\n",
      "        115, 115, 115, 115])\n",
      "tensor([115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115,\n",
      "        115, 115, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116,\n",
      "        116, 116, 116, 116])\n",
      "tensor([116, 116, 116, 116, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
      "        117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118])\n",
      "tensor([118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 119, 119,\n",
      "        119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,\n",
      "        119, 119, 119, 119])\n",
      "tensor([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "        120, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121])\n",
      "tensor([121, 121, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122,\n",
      "        122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "        123, 123, 123, 123])\n",
      "tensor([123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "        123, 123, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "        124, 124, 124, 124])\n",
      "tensor([124, 124, 124, 124, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n",
      "        125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 126, 126, 126, 126,\n",
      "        126, 126, 126, 126])\n",
      "tensor([126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127, 127,\n",
      "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
      "        127, 127, 127, 127])\n",
      "tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129])\n",
      "tensor([129, 129, 129, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130,\n",
      "        130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130, 130,\n",
      "        131, 131, 131, 131])\n",
      "tensor([131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        131, 131, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132])\n",
      "tensor([132, 132, 132, 132, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
      "        133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 134, 134, 134, 134,\n",
      "        134, 134, 134, 134])\n",
      "tensor([134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 135, 135,\n",
      "        135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135,\n",
      "        135, 135, 135, 135])\n",
      "tensor([136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,\n",
      "        136, 136, 136, 136, 136, 136, 137, 137, 137, 137, 137, 137, 137, 137,\n",
      "        137, 137, 137, 137])\n",
      "tensor([137, 137, 137, 137, 137, 137, 137, 137, 138, 138, 138, 138, 138, 138,\n",
      "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
      "        139, 139, 139, 139])\n",
      "tensor([139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
      "        139, 139, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,\n",
      "        140, 140, 140, 140])\n",
      "tensor([140, 140, 140, 140, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141,\n",
      "        141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142])\n",
      "tensor([142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143])\n",
      "tensor([144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144,\n",
      "        144, 144, 144, 144, 144, 144, 145, 145, 145, 145, 145, 145, 145, 145,\n",
      "        145, 145, 145, 145])\n",
      "tensor([145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 146, 146, 146, 146,\n",
      "        146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146,\n",
      "        147, 147, 147, 147])\n",
      "tensor([147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,\n",
      "        148, 148, 148, 148])\n",
      "tensor([148, 148, 148, 148, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150])\n",
      "tensor([150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
      "        150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150])\n"
     ]
    }
   ],
   "source": [
    "for batch in valid_loader:\n",
    "# for batch in train_loader:\n",
    "    print(batch[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-cemetery",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "frequent-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_loss(x, y, num_cls, w, \n",
    "             reuse=False, alpha=0.35, beta=0.35, scale=64, \n",
    "             lamb1=1, lamb2=10, ce_loss_oos=False, name='cos_margin_loss'):\n",
    "    '''\n",
    "    x: B x D - features\n",
    "    y: B - labels\n",
    "    num_cls: 1 - total class number, the last cls being out of scope\n",
    "    w: num_cls x D - mean feature vectors (centroids)\n",
    "    alpah: 1 - in scope margin\n",
    "    beta: 1 - out of scope margin\n",
    "    scale: 1 - scaling paramter\n",
    "    lamb1: weight of 1-cosine\n",
    "    lamb2: weight of max\n",
    "    ce_loss_oos: calculate oos loss in cross entropy\n",
    "    ''' \n",
    "    #normalize the feature and weight\n",
    "    #(B,D)\n",
    "    x_feat_norm = F.normalize(x,p=2,dim=1,eps=1e-12)\n",
    "    #(D,num_cls)\n",
    "    w_feat_norm = torch.transpose(F.normalize(w,p=2,dim=1,eps=1e-12), 0, 1)\n",
    "\n",
    "    # get the scores after normalization \n",
    "    #(B,num_cls)\n",
    "    xw_norm = torch.matmul(x_feat_norm, w_feat_norm)  # cosine similarity\n",
    "\n",
    "    # xbj's loss, first row, adjust the cosine similarity by a margin, only apply to in-scope instances\n",
    "    xw_norm[:, :-1] -= alpha #(B,num_cls)\n",
    "#     xw_norm[:, -1] -= alpha #(B,num_cls)\n",
    "\n",
    "    # margin based softmax loss\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    ce_loss = loss_fn(xw_norm, y)\n",
    "    if not ce_loss_oos:\n",
    "        ce_loss[y == 150] = 0\n",
    "#     print(\"ce_loss shape: \", ce_loss.shape)\n",
    "    \n",
    "    # xbj loss, second row, only applies to out of scope instances\n",
    "    out_of_scope_loss_part2 = torch.max(xw_norm[:, :-1] - alpha, dim=1)[0] - xw_norm[:, -1]\n",
    "    out_of_scope_loss_part2[out_of_scope_loss_part2 < 0] = 0\n",
    "#     print(\"out_of_scope_loss_part2 shape: \", out_of_scope_loss_part2.shape)\n",
    "    out_of_scope_loss = lamb1 * (1 - xw_norm[:, -1]) + lamb2 * out_of_scope_loss_part2\n",
    "#     print(\"out_of_scope_loss shape: \", out_of_scope_loss.shape)\n",
    "       \n",
    "    out_of_scope_loss[y < 150] = 0\n",
    "    \n",
    "    loss = torch.mean(ce_loss + out_of_scope_loss)\n",
    "    \n",
    "    return loss \n",
    "\n",
    "def predict(x, w, alpha=0.35):\n",
    "    '''\n",
    "    x: B x D - features\n",
    "    w: num_cls x D - mean feature vectors (centroids)\n",
    "    ''' \n",
    "    #normalize the feature and weight\n",
    "    #(B,D)\n",
    "#     print(\"x.size():\", x.size())\n",
    "    x_feat_norm = F.normalize(x,p=2,dim=1,eps=1e-12)\n",
    "    #(D,num_cls)\n",
    "    w_feat_norm = torch.transpose(F.normalize(w,p=2,dim=1,eps=1e-12), 0, 1)\n",
    "\n",
    "    # get the scores after normalization \n",
    "    #(B,num_cls)\n",
    "    xw_norm = torch.matmul(x_feat_norm, w_feat_norm)  # cosine similarity\n",
    "\n",
    "    xw_norm[:, :-1] -= alpha\n",
    "    \n",
    "    preds = xw_norm.max(1)[1]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medieval-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cognitive-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(args.bert_model)\n",
    "def get_optimizer(bert_model, args):\n",
    "    param_optimizer = list(bert_model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr = args.lr)   \n",
    "    return optimizer\n",
    "optimizer = get_optimizer(bert_model, args)\n",
    "    \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id           \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "former-ghana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing centroids...\n"
     ]
    }
   ],
   "source": [
    "def compute_centroids(dataloader, bert_model):\n",
    "    print(\"Computing centroids...\")\n",
    "    vectors = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(dataloader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "            token_type_ids = token_type_ids.to(DEVICE)\n",
    "            outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "            pooler_output = outputs.pooler_output\n",
    "            vectors.append(pooler_output.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    vectors = torch.cat(vectors, 0) # num_ins, feature_dim\n",
    "    labels = torch.cat(all_labels, 0) # num_ins\n",
    "    w = []\n",
    "    for i in range(151):\n",
    "        w.append(vectors[labels==i].mean(0, keepdim=True))\n",
    "    w = torch.cat(w, 0)\n",
    "    return w\n",
    "w = compute_centroids(valid_loader, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "muslim-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecological-career",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "arctic-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloder, w):\n",
    "    w = w.to(DEVICE)\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(dataloder):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "            token_type_ids = token_type_ids.to(DEVICE)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "            pooler_output  = outputs.pooler_output \n",
    "\n",
    "            preds = predict(pooler_output, w, alpha=0.35).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "    preds = torch.cat(all_preds)\n",
    "    labels = torch.cat(all_labels)\n",
    "    accuracy = torch.sum(preds == labels).item() / labels.shape[0]\n",
    "    \n",
    "    all_recalls = [torch.sum(preds[labels==i] == labels[labels==i]).item() / torch.sum(labels == i).item() for i in range(150)]\n",
    "    out_of_scope_recall = torch.sum(preds[labels==150] == labels[labels==150]).item() / torch.sum(labels == 150).item()\n",
    "    out_of_scope_precision = torch.sum(preds[labels==150] == labels[labels==150]).item() / torch.sum(preds == 150).item()\n",
    "    in_scope_accuracy = torch.sum(preds[labels<150] == labels[labels<150]).item() / torch.sum(labels < 150).item()\n",
    "    \n",
    "    metrics = {\"accuracy\": accuracy, \n",
    "               \"out_of_scope_recall\": out_of_scope_recall, \n",
    "               \"out_of_scope_precision\": out_of_scope_precision,\n",
    "               \"in_scope_accuracy\": in_scope_accuracy,\n",
    "               \"all_recalls\": all_recalls,}\n",
    "    \n",
    "#     print(\"accuracy: \", accuracy, \"out of scope recall: \", out_of_scope_recall, \"out of scope precision: \", out_of_scope_precision)\n",
    "#     print(\"all_recalls: \", all_recalls)\n",
    "#     print(\"in_scope_accuracy: \", in_scope_accuracy)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-submission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing centroids...\n",
      "[1] loss: 4.909\n",
      "{'accuracy': 0.03774193548387097, 'out_of_scope_recall': 0.98, 'out_of_scope_precision': 0.0394842868654311, 'in_scope_accuracy': 0.006333333333333333, 'all_recalls': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.95, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
      "{'accuracy': 0.17927272727272728, 'out_of_scope_recall': 0.953, 'out_of_scope_precision': 0.2114019520851819, 'in_scope_accuracy': 0.007333333333333333, 'all_recalls': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
      "Computing centroids...\n",
      "[2] loss: 4.228\n",
      "{'accuracy': 0.8406451612903226, 'out_of_scope_recall': 0.74, 'out_of_scope_precision': 0.6491228070175439, 'in_scope_accuracy': 0.844, 'all_recalls': [0.95, 0.85, 1.0, 0.75, 0.85, 0.95, 1.0, 0.95, 1.0, 0.45, 0.0, 0.85, 0.25, 0.6, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.8, 0.85, 1.0, 0.7, 0.85, 0.95, 0.85, 1.0, 0.6, 0.9, 0.7, 1.0, 0.65, 0.65, 0.85, 1.0, 0.55, 0.95, 0.75, 0.95, 0.9, 1.0, 0.7, 0.3, 0.95, 0.85, 0.45, 0.75, 1.0, 0.55, 1.0, 0.9, 0.7, 0.9, 0.3, 0.95, 1.0, 0.95, 1.0, 1.0, 0.55, 0.85, 0.8, 0.95, 1.0, 1.0, 0.55, 1.0, 0.95, 0.8, 0.9, 0.95, 1.0, 0.9, 0.7, 0.65, 0.45, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.9, 0.7, 1.0, 0.6, 0.8, 1.0, 0.5, 0.5, 1.0, 1.0, 0.8, 1.0, 1.0, 0.65, 0.95, 0.95, 0.8, 0.95, 0.8, 0.9, 0.75, 1.0, 0.95, 0.75, 1.0, 0.9, 1.0, 0.9, 0.55, 0.9, 0.95, 0.95, 1.0, 0.95, 1.0, 0.85, 0.9, 0.9, 1.0, 0.95, 0.85, 0.6, 1.0, 1.0, 0.2, 0.95, 0.8, 0.9, 0.6, 1.0, 0.8, 1.0, 0.9, 0.85, 0.9, 0.95, 0.7, 0.95, 0.35, 0.8, 0.95, 0.95, 1.0]}\n",
      "{'accuracy': 0.78, 'out_of_scope_recall': 0.498, 'out_of_scope_precision': 0.9005424954792043, 'in_scope_accuracy': 0.8426666666666667, 'all_recalls': [0.9666666666666667, 0.8666666666666667, 0.9333333333333333, 0.8, 0.9333333333333333, 0.8333333333333334, 0.9333333333333333, 0.9, 0.7666666666666667, 0.3, 0.0, 0.9333333333333333, 0.26666666666666666, 0.7, 0.9333333333333333, 1.0, 1.0, 1.0, 0.6, 0.9666666666666667, 0.9333333333333333, 0.7333333333333333, 0.8333333333333334, 1.0, 0.8333333333333334, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.4, 0.7666666666666667, 0.9, 0.8333333333333334, 0.8, 0.6666666666666666, 0.9, 0.9333333333333333, 0.7666666666666667, 0.8666666666666667, 0.7666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 0.8333333333333334, 0.43333333333333335, 0.9333333333333333, 0.6333333333333333, 0.8666666666666667, 1.0, 1.0, 0.5333333333333333, 0.8, 0.9666666666666667, 0.8333333333333334, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9, 0.9666666666666667, 0.9666666666666667, 0.6333333333333333, 0.8333333333333334, 0.7666666666666667, 0.8333333333333334, 0.9666666666666667, 0.9666666666666667, 0.6666666666666666, 0.9333333333333333, 0.7666666666666667, 0.5, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9333333333333333, 0.6333333333333333, 0.6333333333333333, 0.7, 0.9666666666666667, 0.7666666666666667, 0.6, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.6, 0.8666666666666667, 0.6, 0.7666666666666667, 0.7333333333333333, 0.8333333333333334, 0.7666666666666667, 0.8333333333333334, 0.9, 0.8333333333333334, 0.9666666666666667, 1.0, 0.8, 1.0, 0.7666666666666667, 0.7, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.8666666666666667, 0.8, 0.9333333333333333, 1.0, 0.9333333333333333, 0.6, 1.0, 0.8666666666666667, 1.0, 0.9333333333333333, 0.8666666666666667, 0.9, 0.8666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.8333333333333334, 0.9333333333333333, 0.4, 0.9666666666666667, 0.7333333333333333, 0.16666666666666666, 0.9333333333333333, 0.9333333333333333, 1.0, 0.7666666666666667, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.7666666666666667, 1.0, 0.5333333333333333, 1.0, 0.4, 0.8666666666666667, 1.0, 1.0, 0.7333333333333333]}\n",
      "Computing centroids...\n",
      "[3] loss: 4.120\n",
      "{'accuracy': 0.8958064516129032, 'out_of_scope_recall': 0.72, 'out_of_scope_precision': 0.6666666666666666, 'in_scope_accuracy': 0.9016666666666666, 'all_recalls': [0.95, 0.9, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 0.85, 0.0, 0.95, 0.65, 0.75, 0.85, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.65, 1.0, 0.7, 0.9, 0.85, 0.95, 1.0, 1.0, 0.8, 0.8, 0.95, 1.0, 0.75, 0.9, 1.0, 0.8, 0.9, 0.85, 0.95, 0.85, 1.0, 0.75, 1.0, 1.0, 0.85, 0.8, 0.95, 1.0, 0.7, 1.0, 1.0, 0.9, 0.95, 0.45, 0.95, 1.0, 0.95, 1.0, 1.0, 0.65, 0.95, 0.85, 1.0, 1.0, 1.0, 0.95, 0.95, 0.9, 0.35, 0.95, 0.9, 1.0, 0.95, 0.8, 0.95, 0.8, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 0.9, 1.0, 1.0, 0.85, 0.9, 1.0, 0.65, 0.55, 1.0, 1.0, 0.9, 1.0, 1.0, 0.65, 1.0, 0.95, 0.9, 0.95, 1.0, 0.9, 0.8, 1.0, 0.95, 0.9, 1.0, 0.9, 1.0, 0.9, 0.85, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.9, 0.95, 0.9, 1.0, 0.9, 0.85, 0.55, 1.0, 0.95, 0.55, 0.95, 0.85, 0.9, 0.6, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 0.9, 0.8, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8285454545454546, 'out_of_scope_recall': 0.503, 'out_of_scope_precision': 0.9063063063063063, 'in_scope_accuracy': 0.9008888888888889, 'all_recalls': [0.9666666666666667, 0.9, 0.9333333333333333, 0.7666666666666667, 0.9333333333333333, 0.8333333333333334, 0.9666666666666667, 1.0, 0.7666666666666667, 0.7333333333333333, 0.0, 0.9333333333333333, 0.8, 0.8333333333333334, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.6, 0.9666666666666667, 0.8333333333333334, 0.9333333333333333, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.7666666666666667, 0.9333333333333333, 0.8, 0.9333333333333333, 0.7, 0.9333333333333333, 1.0, 0.8, 0.8, 0.8333333333333334, 1.0, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 1.0, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 0.7333333333333333, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.7, 0.8666666666666667, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 0.8666666666666667, 0.9, 0.8, 0.43333333333333335, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 1.0, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.7, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 1.0, 0.8333333333333334, 0.6333333333333333, 0.8333333333333334, 0.8, 0.8333333333333334, 0.8666666666666667, 0.8333333333333334, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9, 1.0, 0.8333333333333334, 0.7, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9, 0.8333333333333334, 0.9333333333333333, 1.0, 0.9666666666666667, 0.8, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9, 0.9, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9333333333333333, 0.4666666666666667, 0.9333333333333333, 0.8, 0.8, 1.0, 0.9333333333333333, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.8666666666666667, 1.0, 0.6, 1.0, 0.9, 0.8666666666666667, 0.9666666666666667, 1.0, 0.8]}\n",
      "Computing centroids...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] loss: 4.085\n",
      "{'accuracy': 0.917741935483871, 'out_of_scope_recall': 0.72, 'out_of_scope_precision': 0.6792452830188679, 'in_scope_accuracy': 0.9243333333333333, 'all_recalls': [0.95, 0.9, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 0.85, 0.0, 1.0, 0.7, 0.85, 0.85, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.75, 1.0, 0.7, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.8, 1.0, 1.0, 0.75, 0.9, 1.0, 0.85, 0.95, 0.85, 0.95, 0.85, 1.0, 0.75, 1.0, 1.0, 0.8, 0.85, 0.95, 0.95, 0.75, 1.0, 1.0, 0.9, 1.0, 0.55, 0.9, 1.0, 1.0, 1.0, 1.0, 0.7, 0.95, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.85, 0.95, 0.95, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65, 0.7, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 0.85, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.95, 0.85, 0.8, 1.0, 1.0, 0.85, 0.95, 0.85, 0.9, 0.65, 0.95, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85, 1.0, 0.9, 0.85, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8405454545454546, 'out_of_scope_recall': 0.495, 'out_of_scope_precision': 0.9016393442622951, 'in_scope_accuracy': 0.9173333333333333, 'all_recalls': [1.0, 0.9, 0.9333333333333333, 0.5, 0.9, 0.8333333333333334, 0.9666666666666667, 1.0, 0.8333333333333334, 0.7666666666666667, 0.0, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9, 0.9333333333333333, 0.9666666666666667, 0.7, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8, 0.9333333333333333, 0.8333333333333334, 0.9666666666666667, 0.7333333333333333, 0.9666666666666667, 1.0, 0.8666666666666667, 0.8, 0.8666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8333333333333334, 1.0, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667, 1.0, 1.0, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 0.9, 0.9666666666666667, 0.9, 1.0, 1.0, 0.8666666666666667, 0.9, 0.9, 0.6, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 1.0, 0.9666666666666667, 0.7666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.7333333333333333, 0.9333333333333333, 0.8333333333333334, 0.8, 0.9666666666666667, 0.8333333333333334, 0.9, 0.8666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.8, 0.7, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.7666666666666667, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.8333333333333334, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9, 0.7666666666666667, 0.9666666666666667, 0.8, 0.8333333333333334, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.6333333333333333, 1.0, 0.9, 0.8666666666666667, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n",
      "[5] loss: 4.067\n",
      "{'accuracy': 0.9206451612903226, 'out_of_scope_recall': 0.7, 'out_of_scope_precision': 0.660377358490566, 'in_scope_accuracy': 0.928, 'all_recalls': [0.95, 0.9, 1.0, 0.7, 0.85, 0.95, 0.95, 1.0, 1.0, 0.9, 0.0, 1.0, 0.8, 0.85, 0.85, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.75, 1.0, 0.7, 0.85, 1.0, 0.95, 1.0, 0.95, 0.9, 0.85, 1.0, 1.0, 0.8, 0.9, 1.0, 0.75, 0.85, 0.85, 0.95, 0.9, 1.0, 0.8, 1.0, 1.0, 0.85, 0.85, 0.95, 1.0, 0.75, 1.0, 1.0, 0.9, 1.0, 0.55, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.75, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.55, 1.0, 1.0, 0.95, 1.0, 1.0, 0.75, 1.0, 1.0, 0.85, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.85, 1.0, 0.95, 1.0, 0.9, 0.8, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.9, 1.0, 0.9, 0.85, 0.85, 1.0, 1.0, 0.95, 0.95, 0.85, 0.9, 0.65, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.95, 0.85, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8429090909090909, 'out_of_scope_recall': 0.488, 'out_of_scope_precision': 0.9003690036900369, 'in_scope_accuracy': 0.9217777777777778, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.5333333333333333, 0.9, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.8333333333333334, 0.7666666666666667, 0.0, 1.0, 0.8666666666666667, 0.9, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.6666666666666666, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.7666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.8, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8333333333333334, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.8, 0.9666666666666667, 0.9, 1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 0.8666666666666667, 0.4666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.8, 0.9333333333333333, 0.8, 0.8666666666666667, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.8333333333333334, 0.7666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9, 0.9, 0.8333333333333334, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9, 0.8, 0.9333333333333333, 0.7666666666666667, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.6666666666666666, 1.0, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 0.7666666666666667]}\n",
      "Computing centroids...\n",
      "[6] loss: 4.055\n",
      "{'accuracy': 0.9258064516129032, 'out_of_scope_recall': 0.66, 'out_of_scope_precision': 0.6407766990291263, 'in_scope_accuracy': 0.9346666666666666, 'all_recalls': [0.95, 0.9, 1.0, 0.65, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 1.0, 0.95, 1.0, 0.95, 0.9, 0.9, 1.0, 1.0, 0.75, 0.9, 1.0, 0.9, 0.95, 0.85, 0.9, 0.9, 1.0, 0.9, 1.0, 1.0, 0.85, 0.85, 0.95, 1.0, 0.75, 1.0, 1.0, 0.95, 1.0, 0.65, 0.95, 1.0, 1.0, 1.0, 1.0, 0.65, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.7, 1.0, 1.0, 0.8, 1.0, 1.0, 0.85, 0.95, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.95, 0.85, 0.85, 1.0, 0.9, 1.0, 0.95, 0.85, 0.9, 0.65, 0.9, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.85, 0.95, 0.95, 1.0]}\n",
      "{'accuracy': 0.846909090909091, 'out_of_scope_recall': 0.487, 'out_of_scope_precision': 0.8968692449355433, 'in_scope_accuracy': 0.9268888888888889, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.43333333333333335, 0.9, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.0, 0.9666666666666667, 0.8666666666666667, 0.9, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8, 0.9666666666666667, 0.8666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.7333333333333333, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 0.8666666666666667, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.8666666666666667, 1.0, 0.9333333333333333, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.7, 0.8, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9333333333333333, 0.9, 0.5666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.7666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 0.8333333333333334, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9, 0.8333333333333334, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9333333333333333, 0.8333333333333334, 0.9333333333333333, 0.7666666666666667, 0.8333333333333334, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9, 0.8333333333333334, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] loss: 4.048\n",
      "{'accuracy': 0.9235483870967742, 'out_of_scope_recall': 0.66, 'out_of_scope_precision': 0.6226415094339622, 'in_scope_accuracy': 0.9323333333333333, 'all_recalls': [1.0, 0.9, 1.0, 0.5, 0.85, 0.95, 0.9, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.8, 1.0, 0.7, 0.9, 1.0, 0.95, 1.0, 0.95, 0.9, 0.9, 1.0, 1.0, 0.85, 0.9, 1.0, 0.9, 0.9, 0.85, 0.9, 0.9, 1.0, 0.9, 1.0, 0.95, 0.85, 0.85, 0.95, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7, 0.95, 1.0, 1.0, 1.0, 1.0, 0.55, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.9, 0.9, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.7, 1.0, 1.0, 0.95, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.9, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.95, 0.85, 0.85, 1.0, 0.9, 0.9, 0.9, 0.9, 0.9, 0.65, 0.85, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 0.9, 1.0, 0.95, 0.9, 0.95, 0.95, 1.0]}\n",
      "{'accuracy': 0.8467272727272728, 'out_of_scope_recall': 0.469, 'out_of_scope_precision': 0.8967495219885278, 'in_scope_accuracy': 0.9306666666666666, 'all_recalls': [1.0, 0.9333333333333333, 0.9666666666666667, 0.43333333333333335, 0.9, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.0, 1.0, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.8, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.9333333333333333, 1.0, 0.8666666666666667, 0.8333333333333334, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.6333333333333333, 0.8333333333333334, 0.9666666666666667, 0.9, 1.0, 1.0, 0.8666666666666667, 0.9666666666666667, 0.8666666666666667, 0.7666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8333333333333334, 0.9333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9, 0.7333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9333333333333333, 0.8333333333333334, 0.9333333333333333, 0.7666666666666667, 0.8666666666666667, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.8666666666666667, 0.8, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n",
      "[8] loss: 4.043\n",
      "{'accuracy': 0.9290322580645162, 'out_of_scope_recall': 0.64, 'out_of_scope_precision': 0.6336633663366337, 'in_scope_accuracy': 0.9386666666666666, 'all_recalls': [1.0, 0.9, 1.0, 0.65, 0.85, 0.95, 1.0, 1.0, 1.0, 0.9, 0.0, 1.0, 0.8, 0.85, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 1.0, 0.95, 1.0, 0.95, 0.85, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 0.95, 0.9, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.85, 0.95, 0.95, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.7, 1.0, 1.0, 0.95, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.9, 0.8, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.9, 1.0, 0.9, 0.95, 0.95, 0.9, 0.9, 0.65, 0.85, 0.85, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.9, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8492727272727273, 'out_of_scope_recall': 0.468, 'out_of_scope_precision': 0.8897338403041825, 'in_scope_accuracy': 0.934, 'all_recalls': [1.0, 0.9333333333333333, 0.9666666666666667, 0.5333333333333333, 0.9, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9, 0.9333333333333333, 0.0, 1.0, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.8333333333333334, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.7666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.8666666666666667, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9666666666666667, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.8666666666666667, 0.8333333333333334, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.8666666666666667, 0.8333333333333334, 0.9, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.8666666666666667, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8, 0.9, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9666666666666667, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9333333333333333, 0.8, 0.9, 0.7666666666666667, 0.8666666666666667, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9, 0.8666666666666667, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n",
      "[9] loss: 4.039\n",
      "{'accuracy': 0.9274193548387096, 'out_of_scope_recall': 0.62, 'out_of_scope_precision': 0.6526315789473685, 'in_scope_accuracy': 0.9376666666666666, 'all_recalls': [1.0, 0.9, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 1.0, 0.95, 0.9, 0.95, 0.9, 0.9, 1.0, 1.0, 0.75, 0.9, 1.0, 0.9, 0.9, 0.85, 0.95, 0.85, 1.0, 0.95, 1.0, 1.0, 0.85, 0.9, 0.95, 0.95, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.95, 1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 0.75, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.9, 1.0, 0.85, 0.85, 0.95, 0.9, 0.95, 0.65, 0.85, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8443636363636363, 'out_of_scope_recall': 0.436, 'out_of_scope_precision': 0.8879837067209776, 'in_scope_accuracy': 0.9351111111111111, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.6333333333333333, 0.9, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9, 0.0, 1.0, 0.9, 0.9, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.8, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.9333333333333333, 1.0, 0.8666666666666667, 0.9, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.8333333333333334, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8666666666666667, 0.8666666666666667, 0.9666666666666667, 0.8, 0.8666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 1.0, 0.8333333333333334, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9333333333333333, 0.8666666666666667, 0.9, 0.7, 0.8666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.7333333333333333, 1.0, 0.8666666666666667, 0.8, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] loss: 4.036\n",
      "{'accuracy': 0.927741935483871, 'out_of_scope_recall': 0.62, 'out_of_scope_precision': 0.6526315789473685, 'in_scope_accuracy': 0.938, 'all_recalls': [0.95, 0.9, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 1.0, 0.95, 0.9, 0.95, 0.85, 0.9, 1.0, 1.0, 0.8, 0.9, 1.0, 0.9, 0.85, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.9, 0.9, 0.95, 0.95, 0.75, 1.0, 1.0, 1.0, 1.0, 0.8, 0.95, 1.0, 1.0, 1.0, 1.0, 0.55, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.7, 0.7, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 0.9, 0.9, 1.0, 1.0, 0.95, 1.0, 0.9, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.9, 0.95, 0.95, 0.9, 0.95, 0.65, 0.85, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.846909090909091, 'out_of_scope_recall': 0.445, 'out_of_scope_precision': 0.9063136456211812, 'in_scope_accuracy': 0.9362222222222222, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.6666666666666666, 0.9, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.0, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.9666666666666667, 1.0, 0.9, 0.8, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.5666666666666667, 0.8333333333333334, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 0.8, 0.8666666666666667, 0.9333333333333333, 0.8, 0.8666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.8666666666666667, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 1.0, 1.0, 0.8666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9, 0.9333333333333333, 0.8333333333333334, 0.8666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 1.0, 0.8666666666666667, 0.7666666666666667, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n",
      "[11] loss: 4.033\n",
      "{'accuracy': 0.932258064516129, 'out_of_scope_recall': 0.63, 'out_of_scope_precision': 0.6631578947368421, 'in_scope_accuracy': 0.9423333333333334, 'all_recalls': [0.95, 0.95, 1.0, 0.8, 0.85, 0.95, 0.9, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 0.95, 0.9, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 1.0, 1.0, 0.85, 0.95, 0.9, 1.0, 0.9, 1.0, 1.0, 0.9, 0.9, 0.95, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.8, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.65, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 0.8, 0.85, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 0.95, 0.85, 0.95, 1.0, 0.85, 0.9, 0.95, 0.85, 0.95, 0.65, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8454545454545455, 'out_of_scope_recall': 0.44, 'out_of_scope_precision': 0.8961303462321792, 'in_scope_accuracy': 0.9355555555555556, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.6666666666666666, 0.9, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.0, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9333333333333333, 0.8333333333333334, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.8, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 1.0, 0.9666666666666667, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 0.8666666666666667, 0.9666666666666667, 0.9, 0.8333333333333334, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.7666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9333333333333333, 0.9, 1.0, 1.0, 1.0, 0.6333333333333333, 0.8666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9333333333333333, 0.8333333333333334, 0.9333333333333333, 0.7666666666666667, 0.8666666666666667, 1.0, 0.9, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.7333333333333333, 1.0, 0.9, 0.7666666666666667, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n",
      "[12] loss: 4.031\n",
      "{'accuracy': 0.9306451612903226, 'out_of_scope_recall': 0.62, 'out_of_scope_precision': 0.6526315789473685, 'in_scope_accuracy': 0.941, 'all_recalls': [1.0, 0.95, 1.0, 0.7, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 0.0, 1.0, 0.8, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 0.95, 0.9, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 0.95, 0.9, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.9, 0.95, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 0.75, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.7, 0.65, 1.0, 1.0, 0.85, 0.95, 1.0, 0.8, 0.95, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.9, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.9, 0.95, 0.95, 0.85, 0.9, 0.65, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.9, 0.95, 0.95, 1.0]}\n",
      "{'accuracy': 0.848909090909091, 'out_of_scope_recall': 0.438, 'out_of_scope_precision': 0.9012345679012346, 'in_scope_accuracy': 0.9402222222222222, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.6333333333333333, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.0, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.8333333333333334, 0.9, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9, 0.8, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9, 0.9666666666666667, 0.7666666666666667, 0.8666666666666667, 1.0, 0.9, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9, 0.8, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] loss: 4.029\n",
      "{'accuracy': 0.9332258064516129, 'out_of_scope_recall': 0.6, 'out_of_scope_precision': 0.6818181818181818, 'in_scope_accuracy': 0.9443333333333334, 'all_recalls': [1.0, 0.95, 1.0, 0.95, 0.85, 0.95, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.8, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 1.0, 0.9, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 0.9, 1.0, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.9, 0.95, 0.9, 0.75, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 0.6, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.85, 0.9, 0.95, 0.9, 0.9, 0.65, 0.9, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8447272727272728, 'out_of_scope_recall': 0.419, 'out_of_scope_precision': 0.9088937093275488, 'in_scope_accuracy': 0.9393333333333334, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.7666666666666667, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.8, 0.0, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7333333333333333, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.9, 0.9, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.9, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8, 0.9, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.7666666666666667, 0.8, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.5333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 0.8333333333333334, 0.9666666666666667, 0.7333333333333333, 0.8666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9333333333333333, 0.8, 1.0, 1.0, 0.8333333333333334]}\n",
      "Computing centroids...\n",
      "[14] loss: 4.027\n",
      "{'accuracy': 0.9335483870967742, 'out_of_scope_recall': 0.61, 'out_of_scope_precision': 0.6777777777777778, 'in_scope_accuracy': 0.9443333333333334, 'all_recalls': [1.0, 0.95, 1.0, 0.9, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 0.0, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 0.95, 0.95, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 0.9, 0.95, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.9, 0.95, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.7, 0.8, 1.0, 1.0, 0.85, 0.95, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.85, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.85, 0.95, 0.95, 0.9, 0.95, 0.65, 0.9, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8474545454545455, 'out_of_scope_recall': 0.425, 'out_of_scope_precision': 0.9042553191489362, 'in_scope_accuracy': 0.9413333333333334, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.7, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.03333333333333333, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.8666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.9, 0.9, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8666666666666667, 0.8666666666666667, 0.9666666666666667, 0.8, 0.9, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.9, 1.0, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9, 0.9, 0.9333333333333333, 0.7666666666666667, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9333333333333333, 0.7666666666666667, 1.0, 1.0, 0.8333333333333334]}\n",
      "Computing centroids...\n",
      "[15] loss: 4.025\n",
      "{'accuracy': 0.9312903225806451, 'out_of_scope_recall': 0.54, 'out_of_scope_precision': 0.6835443037974683, 'in_scope_accuracy': 0.9443333333333334, 'all_recalls': [1.0, 0.95, 1.0, 0.95, 0.85, 0.95, 0.95, 1.0, 1.0, 0.85, 0.15, 1.0, 0.75, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 0.95, 0.95, 0.9, 1.0, 1.0, 0.8, 0.95, 1.0, 0.9, 1.0, 0.85, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 0.85, 0.9, 0.95, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 0.95, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.7, 0.75, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 1.0, 0.9, 0.95, 1.0, 0.95, 0.9, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.85, 0.9, 0.95, 0.9, 0.95, 0.65, 0.8, 0.9, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8427272727272728, 'out_of_scope_recall': 0.401, 'out_of_scope_precision': 0.9134396355353075, 'in_scope_accuracy': 0.9408888888888889, 'all_recalls': [1.0, 0.9, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 1.0, 0.9, 0.8666666666666667, 0.1, 1.0, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9666666666666667, 0.9666666666666667, 1.0, 0.7666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9, 0.9, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.7666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.8666666666666667, 0.9, 0.9, 0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8333333333333334, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 0.9333333333333333, 0.8, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 0.8333333333333334, 0.7333333333333333, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9666666666666667, 0.9333333333333333, 0.8666666666666667, 0.9666666666666667, 0.7, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333, 1.0, 0.9, 0.8, 1.0, 1.0, 0.8]}\n",
      "Computing centroids...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] loss: 4.025\n",
      "{'accuracy': 0.9225806451612903, 'out_of_scope_recall': 0.57, 'out_of_scope_precision': 0.6785714285714286, 'in_scope_accuracy': 0.9343333333333333, 'all_recalls': [0.95, 0.95, 1.0, 0.9, 0.85, 0.95, 0.95, 1.0, 1.0, 0.95, 0.15, 1.0, 0.8, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.95, 1.0, 0.95, 0.95, 0.75, 0.9, 0.9, 1.0, 0.9, 1.0, 1.0, 0.9, 0.9, 0.95, 0.9, 0.7, 1.0, 1.0, 0.95, 1.0, 0.8, 0.95, 1.0, 1.0, 1.0, 1.0, 0.35, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.9, 0.8, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.75, 0.5, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 1.0, 0.85, 0.95, 1.0, 1.0, 0.85, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.85, 0.95, 0.95, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0, 0.95, 0.9, 1.0, 1.0, 0.85, 0.9, 1.0, 0.85, 0.95, 0.9, 0.9, 0.95, 0.65, 0.8, 0.9, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.85, 0.95, 0.9, 1.0]}\n",
      "{'accuracy': 0.8405454545454546, 'out_of_scope_recall': 0.429, 'out_of_scope_precision': 0.9225806451612903, 'in_scope_accuracy': 0.932, 'all_recalls': [1.0, 0.9333333333333333, 0.9666666666666667, 0.8333333333333334, 0.9666666666666667, 0.8666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9, 0.9333333333333333, 0.06666666666666667, 0.9666666666666667, 0.9, 0.9, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7666666666666667, 0.9333333333333333, 0.9666666666666667, 1.0, 0.8, 1.0, 1.0, 0.9, 0.8666666666666667, 0.7333333333333333, 0.9333333333333333, 0.9, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.2, 0.8666666666666667, 0.9333333333333333, 0.9, 1.0, 1.0, 0.9, 0.9666666666666667, 0.9, 0.9333333333333333, 0.8333333333333334, 0.9333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8666666666666667, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.8333333333333334, 0.8333333333333334, 0.9666666666666667, 0.8333333333333334, 0.8666666666666667, 0.9666666666666667, 0.8, 0.8666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 0.9666666666666667, 0.8, 0.7666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9333333333333333, 0.9333333333333333, 1.0, 1.0, 1.0, 0.8, 1.0, 0.9666666666666667, 0.9, 1.0, 0.9, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9, 0.9666666666666667, 0.6666666666666666, 0.8666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.7333333333333333, 0.9666666666666667, 0.9, 0.8333333333333334, 1.0, 1.0, 0.8333333333333334]}\n",
      "Computing centroids...\n"
     ]
    }
   ],
   "source": [
    "LAMB1 = 1\n",
    "LAMB2 = 10\n",
    "CE_LOSS_OOS = False\n",
    "ALPHA = 0.35\n",
    "CHECKPOINT_PATH = \"checkpoints/alpha_{}_lamb1_{}_lamb2_{}_celossoos_{}\".format(ALPHA, LAMB1, LAMB2, CE_LOSS_OOS)\n",
    "!mkdir -p $CHECKPOINT_PATH\n",
    "\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "\n",
    "    w = compute_centroids(train_loader, bert_model).detach().to(DEVICE)\n",
    "    last_w = w.cpu()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_loader):\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "        token_type_ids = token_type_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        pooler_output  = outputs.pooler_output \n",
    "#         print(\"y.size():\", y.size())\n",
    "        \n",
    "        loss = cos_loss(pooler_output, labels, 151, w, alpha=ALPHA, \n",
    "                        lamb1=LAMB1, lamb2=LAMB2, ce_loss_oos=CE_LOSS_OOS,\n",
    "                        beta=0.35, scale=64, name='cos_margin_loss')\n",
    "#         print(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('[%d] loss: %.3f' %\n",
    "          (epoch + 1, running_loss / (i+1)))\n",
    "    metrics = evaluate(valid_loader, last_w)\n",
    "    print(\"valid: \", metrics)\n",
    "    with open(os.path.join(CHECKPOINT_PATH, \"metrics.txt\"), \"a\") as metrics_out:\n",
    "        metrics_out.write(\"epoch {}\\n\".format(epoch+1) + str(metrics) + \"\\n\")\n",
    "    metrics = evaluate(test_loader, last_w)\n",
    "    print(\"test: \", metrics)\n",
    "    with open(os.path.join(CHECKPOINT_PATH, \"test_metrics.txt\"), \"a\") as metrics_out:\n",
    "        metrics_out.write(\"epoch {}\\n\".format(epoch+1) + str(metrics) + \"\\n\")\n",
    "    \n",
    "print('Finished Training')\n",
    "bert_model.save_pretrained(CHECKPOINT_PATH)\n",
    "np.savetxt(os.path.join(CHECKPOINT_PATH, \"last_w.txt\"), last_w.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = BertModel.from_pretrained(CHECKPOINT_PATH)\n",
    "# bert_model.to(DEVICE)\n",
    "# metrics = evaluate(test_loader, last_w)\n",
    "# print(metrics)\n",
    "# with open(os.path.join(CHECKPOINT_PATH, \"test_metrics.txt\"), \"a\") as metrics_out:\n",
    "#     metrics_out.write(str(metrics) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model.save_pretrained(CHECKPOINT_PATH)\n",
    "# np.savetxt(os.path.join(CHECKPOINT_PATH, \"last_w.txt\"), last_w.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-utility",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-creek",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from sklearn.manifold import TSNE\n",
    "# from matplotlib import pyplot as plt\n",
    "# tsne = TSNE(n_components=2, random_state=0)\n",
    "# X_2d = tsne.fit_transform(last_w.numpy())\n",
    "\n",
    "# target_ids = range(len(idx_to_type))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# for i, label in zip(target_ids, idx_to_type):\n",
    "#     plt.scatter(X_2d[i, 0], X_2d[i, 1], label=label)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_for_visualization(dataloder, w):\n",
    "#     w = w.to(DEVICE)\n",
    "#     all_labels = []\n",
    "#     all_vectors = []\n",
    "#     with torch.no_grad():\n",
    "#         for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(dataloder):\n",
    "#             input_ids = input_ids.to(DEVICE)\n",
    "#             attention_mask = attention_mask.to(DEVICE)\n",
    "#             token_type_ids = token_type_ids.to(DEVICE)\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = bert_model(input_ids, attention_mask, token_type_ids)\n",
    "#             pooler_output  = outputs.pooler_output \n",
    "\n",
    "#             all_vectors.append(pooler_output)\n",
    "#             all_labels.append(labels)\n",
    "            \n",
    "#     labels = torch.cat(all_labels)\n",
    "#     vectors = torch.cat(all_vectors, 0)\n",
    "    \n",
    "#     return labels.cpu().numpy(), vectors.cpu().numpy()\n",
    "# labels, vectors = predict_for_visualization(train_loader, last_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors.shape\n",
    "# vectors_and_weights = np.concatenate([vectors, last_w.numpy()], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors_and_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-conservation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from sklearn.manifold import TSNE\n",
    "# from matplotlib import pyplot as plt\n",
    "# tsne = TSNE(n_components=2, random_state=0)\n",
    "# X_2d = tsne.fit_transform(vectors_and_weights)\n",
    "\n",
    "# target_ids = range(len(idx_to_type[:]))\n",
    "# X_2d_vectors = X_2d[:-151]\n",
    "# X_2d_w = X_2d[-151:]\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# for i, label in zip(target_ids, idx_to_type[:]):\n",
    "#     if i == 150:\n",
    "#         plt.scatter(X_2d_vectors[labels==i, 0], X_2d_vectors[labels==i, 1], c='k', label=label)\n",
    "#         plt.scatter(X_2d_w[i, 0], X_2d_w[i, 1], c='k', label=label+\"_w\")\n",
    "#     elif i > 130:\n",
    "#         plt.scatter(X_2d_vectors[labels==i, 0], X_2d_vectors[labels==i, 1], label=label)\n",
    "#         plt.scatter(X_2d_w[i, 0], X_2d_w[i, 1], label=label+\"_w\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
